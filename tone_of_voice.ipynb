{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "Requirement already up-to-date: google-cloud-aiplatform in ./.venv/lib/python3.8/site-packages (1.40.0)\n",
      "Requirement already satisfied, skipping upgrade: shapely<3.0.0dev in ./.venv/lib/python3.8/site-packages (from google-cloud-aiplatform) (2.0.2)\n",
      "Requirement already satisfied, skipping upgrade: packaging>=14.3 in ./.venv/lib/python3.8/site-packages (from google-cloud-aiplatform) (23.2)\n",
      "Requirement already satisfied, skipping upgrade: google-cloud-bigquery<4.0.0dev,>=1.15.0 in ./.venv/lib/python3.8/site-packages (from google-cloud-aiplatform) (3.17.2)\n",
      "Requirement already satisfied, skipping upgrade: proto-plus<2.0.0dev,>=1.22.0 in ./.venv/lib/python3.8/site-packages (from google-cloud-aiplatform) (1.23.0)\n",
      "Requirement already satisfied, skipping upgrade: google-cloud-storage<3.0.0dev,>=1.32.0 in ./.venv/lib/python3.8/site-packages (from google-cloud-aiplatform) (2.14.0)\n",
      "Requirement already satisfied, skipping upgrade: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0 in ./.venv/lib/python3.8/site-packages (from google-cloud-aiplatform) (2.16.2)\n",
      "Requirement already satisfied, skipping upgrade: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in ./.venv/lib/python3.8/site-packages (from google-cloud-aiplatform) (1.12.1)\n",
      "Requirement already satisfied, skipping upgrade: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in ./.venv/lib/python3.8/site-packages (from google-cloud-aiplatform) (4.25.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.14 in ./.venv/lib/python3.8/site-packages (from shapely<3.0.0dev->google-cloud-aiplatform) (1.24.4)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil<3.0dev,>=2.7.2 in ./.venv/lib/python3.8/site-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.8.2)\n",
      "Requirement already satisfied, skipping upgrade: requests<3.0.0dev,>=2.21.0 in ./.venv/lib/python3.8/site-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.31.0)\n",
      "Requirement already satisfied, skipping upgrade: google-resumable-media<3.0dev,>=0.6.0 in ./.venv/lib/python3.8/site-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.7.0)\n",
      "Requirement already satisfied, skipping upgrade: google-cloud-core<3.0.0dev,>=1.6.0 in ./.venv/lib/python3.8/site-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.4.1)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<3.0dev,>=2.23.3 in ./.venv/lib/python3.8/site-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2.27.0)\n",
      "Requirement already satisfied, skipping upgrade: google-crc32c<2.0dev,>=1.0 in ./.venv/lib/python3.8/site-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.5.0)\n",
      "Requirement already satisfied, skipping upgrade: googleapis-common-protos<2.0.dev0,>=1.56.2 in ./.venv/lib/python3.8/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.62.0)\n",
      "Requirement already satisfied, skipping upgrade: grpcio-status<2.0.dev0,>=1.33.2; extra == \"grpc\" in ./.venv/lib/python3.8/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.60.1)\n",
      "Requirement already satisfied, skipping upgrade: grpcio<2.0dev,>=1.33.2; extra == \"grpc\" in ./.venv/lib/python3.8/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.60.1)\n",
      "Requirement already satisfied, skipping upgrade: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in ./.venv/lib/python3.8/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.13.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in ./.venv/lib/python3.8/site-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.16.0)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in ./.venv/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2024.2.2)\n",
      "Requirement already satisfied, skipping upgrade: charset-normalizer<4,>=2 in ./.venv/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (3.3.2)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<3,>=1.21.1 in ./.venv/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.2.0)\n",
      "Requirement already satisfied, skipping upgrade: idna<4,>=2.5 in ./.venv/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (3.6)\n",
      "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4 in ./.venv/lib/python3.8/site-packages (from google-auth<3.0dev,>=2.23.3->google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (4.9)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<6.0,>=2.0.0 in ./.venv/lib/python3.8/site-packages (from google-auth<3.0dev,>=2.23.3->google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (5.3.2)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in ./.venv/lib/python3.8/site-packages (from google-auth<3.0dev,>=2.23.3->google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (0.3.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in ./.venv/lib/python3.8/site-packages (from rsa<5,>=3.1.4->google-auth<3.0dev,>=2.23.3->google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (0.5.1)\n"
     ]
    }
   ],
   "source": [
    "! pip3 install --upgrade google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.preview.generative_models import (\n",
    "    GenerationConfig,\n",
    "    GenerativeModel,\n",
    "    Image,\n",
    "    Part,\n",
    "    HarmBlockThreshold,\n",
    "    HarmCategory,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_model = GenerativeModel(\"gemini-pro\")\n",
    "\n",
    "generation_config = GenerationConfig(\n",
    "    temperature=0.1,\n",
    "    max_output_tokens=2048,\n",
    ")\n",
    "\n",
    "safety_config = {\n",
    "    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_sentiment(voc):\n",
    "  prompt = \"\"\"You are a CPG marketer, You received the customer feedback as the below, analyze the sentiment with score (from 0 to 100) and feelings - ex. curious,  happy, sad, angry, etc.\n",
    "customer feedback : {voc}\n",
    "output : sentiment score, feelings\n",
    "\"\"\"\n",
    "  response = gemini_model.generate_content(prompt.format(voc=voc),generation_config=generation_config, safety_settings=safety_config, stream=False)\n",
    "  return response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = analyze_sentiment(\"ì—¬í–‰ì´ ì¦ê±°ì› ë‚˜?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "role: \"model\"\n",
      "parts {\n",
      "  text: \"Sentiment score: 80\\nFeelings: Curious\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response.candidates[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "role: \"model\"\n",
      "parts {\n",
      "  text: \"Sentiment score: 70\\nFeelings: Curious\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Try more examples\n",
    "print(analyze_sentiment(\"ì—¬í–‰ì€ ì–´ë—˜?\").candidates[0].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, gemini model can detect the emotional(feeling) category from the VoC.\n",
    "\n",
    "Vice versa, we will try to make a phrase with various emotinal conditions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence_with_emotion(business_goal, emotional_condition):\n",
    "  prompt = \"\"\"You are a CPG marketer, create a single question for your customers by combining the given business goal and the desired emotional state.\n",
    "\n",
    "business goal : {business_goal}\n",
    "\n",
    "emotional condition : {emotional_condition}\n",
    "\"\"\"\n",
    "  response = gemini_model.generate_content(prompt.format(business_goal=business_goal, emotional_condition=emotional_condition),generation_config=generation_config, safety_settings=safety_config, stream=False)\n",
    "  return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "role: \"model\"\n",
      "parts {\n",
      "  text: \"ì˜¤ì‚¬ì¹´ì— ë‹¤ë…€ì˜¤ì…¨ëŠ”ë°, ê°€ì¥ ë§˜ì— ë“¤ì—ˆë˜ ê²ƒì´ ë¬´ì—‡ì´ì—ˆëŠ”ì§€ ì•Œë ¤ì£¼ì‹¤ë˜ìš”?ğŸ˜Š\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "business_goal = \"ê¸ˆë²ˆ ì˜¤ì‚¬ì¹´ ì—¬í–‰ì— ëŒ€í•œ ê°ìƒí‰ì„ ë“£ê³  ì‹¶ìŒ\"\n",
    "emotional_condition = \"ì¹œê·¼í•˜ë©° ê²©ì˜ì—†ì´ ì•„ì–‘ ë– ëŠ” ëŠë‚Œìœ¼ë¡œ\"\n",
    "\n",
    "response = generate_sentence_with_emotion(business_goal, emotional_condition)\n",
    "print(response.candidates[0].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's very formal response. Try to make another response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config = GenerationConfig(\n",
    "    temperature=0.8,\n",
    "    max_output_tokens=2048,\n",
    ")\n",
    "\n",
    "safety_config = {\n",
    "    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "role: \"model\"\n",
      "parts {\n",
      "  text: \"ì˜¤ì‚¬ì¹´ì— ê°„ ì¹œêµ¬ë“¤ì—ê²Œ ë¬¼ì–´ë³´ê³  ì‹¶ì€ ë§ í•œ ë§ˆë””ê°€ ìˆë‹¤ë©´?\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emotional_condition = \"ì¹œêµ¬ ì‚¬ì´ì˜ ì§§ì€ ë¬¸ì¥ê³¼ í˜¸ê¸°ì‹¬ì„ ë‹´ì•„ì„œ\"\n",
    "\n",
    "response = generate_sentence_with_emotion(business_goal, emotional_condition)\n",
    "print(response.candidates[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence_with_emotion(business_goal, emotional_condition, generation_config, safety_config):\n",
    "  prompt = \"\"\"Create a single question for your customers by combining the given business goal and the desired tone of voice.\n",
    "\n",
    "business goal : {business_goal}\n",
    "\n",
    "tone of voice : {emotional_condition}\n",
    "\"\"\"\n",
    "  response = gemini_model.generate_content(prompt.format(business_goal=business_goal, emotional_condition=emotional_condition),generation_config=generation_config, safety_settings=safety_config, stream=False)\n",
    "  return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "role: \"model\"\n",
      "parts {\n",
      "  text: \"ì˜¤ì‚¬ì¹´ ê°€ë³¼ ë•Œ ê¼­ ê°€ë´ì•¼ í•  ê³³ì´ ê¶ê¸ˆí•´!\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emotional_condition = \"ì¹œêµ¬ ì‚¬ì´ì˜ ì§§ì€ ë¬¸ì¥ê³¼ í˜¸ê¸°ì‹¬ì„ ë‹´ì•„ì„œ\"\n",
    "\n",
    "response = generate_sentence_with_emotion(business_goal, emotional_condition, generation_config, safety_config)\n",
    "print(response.candidates[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "role: \"model\"\n",
      "parts {\n",
      "  text: \"ì˜¤ì‚¬ì¹´ ì—¬í–‰ì„ ë‹¤ë…€ì˜¤ì‹  ë¶„ë“¤ì˜ ê°ìƒì„ ë“¤ë ¤ì£¼ì„¸ìš”.\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emotional_condition = \"40ëŒ€ì˜ ì¤‘ë…„ ë‚¨ì„± ëŠë‚Œìœ¼ë¡œ ì§§ê²Œ\"\n",
    "\n",
    "response = generate_sentence_with_emotion(business_goal, emotional_condition, generation_config, safety_config)\n",
    "print(response.candidates[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "role: \"model\"\n",
      "parts {\n",
      "  text: \"ì˜¤ì‚¬ì¹´ ê°”ë‹¤ì˜¨ ê²ƒ ìƒê°ë‚˜~? í•µë¿Œë“¯í•œ ê²ƒë“¤ ì†Œê°œí•´ì¤˜ã…“~ ë­ê°€ ì œì¼ ì©ì´ëƒ?\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emotional_condition = \"10ëŒ€ì˜ ì—¬ì„± ì³”êµ¬ ëŠë‚Œìœ¼ë¡œ ì§§ê²Œ\"\n",
    "\n",
    "response = generate_sentence_with_emotion(business_goal, emotional_condition, generation_config, safety_config)\n",
    "print(response.candidates[0].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
